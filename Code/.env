DATA_FILES_JSON_DIR_NAME = dataset_files_json # name of the folder containing the .json-files of the cut and reformatted article data
DATASET_DIR_NAME = arrow_datasets/dataset # name of the folder containing the arrow files for the dataset with duplicates removed 
DATASET_NODATES_DIR_NAME = arrow_datasets/dataset_nodates # name of the folder containing the arrow files for the dataset with dates (DD.MM.YYYY format) removed
DATASET_NODATES_NODUPS_DIR_NAME = arrow_datasets/dataset_nodates_nodups # name of the folder containing the arrow files for the dataset with duplicates removed (second pass, done after removing dates)
DATASET_NODATES_NODUPS_CLEANED_DIR_NAME = arrow_datasets/dataset_nodates_nodups_cleaned # name of the folder containing the arrow files for the no-date, no-dup dataset, cleaned for junk found after "|" and " - "
FILTERED_DATASET_DIR_NAME = arrow_datasets/filtered_dataset # name of the folder containing the arrow files for the cleaned dataset, where entire junk articles have been removed (not just junk substrings)
FILTERED_DATASET_NODUPS_DIR_NAME = arrow_datasets/filtered_dataset_nodups # name of the folder containing the arrow files for the cleaned dataset, where entire junk articles have been removed (not just junk substrings), with duplicates removed
PARTIAL_DATASET_DIR_NAME = arrow_datasets/partial_dataset # name of the folder containing the arrow files for the fully cleaned and reduced dataset, where articles used for fine tuning have been removed and saved somewhere else
ROBERTA_PRETRAIN_INPUT_DIR_NAME = arrow_datasets/roberta_pretrain_input # same as PARTIAL_DATASET_DIR_NAME but with the input data packed like explained in roberta paper
GPT_PRETRAIN_INPUT_DIR_NAME = arrow_datasets/gpt_pretrain_input # same as FILTERED_DATASET_NODUPS_DIR_NAME but with the input data packed like explained in roberta paper

LABELED_MULTI_CLASS_MULTI_LABEL_DATASET_DIR_NAME = arrow_datasets/labeled_multi_class_multi_label_dataset # name of the folder containing the arrow files for the labeled multi-class, multi_label classification dataset
LABELED_MULTI_CLASS_MULTI_LABEL_DATASET_BETTER_DIR_NAME = arrow_datasets/labeled_multi_class_multi_label_dataset_better # name of the folder containing the arrow files for the labeled multi-class, multi_label classification dataset (done right)
LABELED_MULTI_CLASS_MULTI_LABEL_DATASET_BETTER_2000_DIR_NAME = arrow_datasets/labeled_multi_class_multi_label_dataset_better_2000 # name of the folder containing the arrow files for the labeled multi-class, multi_label classification dataset (done right, with 2000 train samples)
LABELED_COVID_CLASS_DATASET_DIR_NAME = arrow_datasets/labeled_covid_class_dataset # name of the folder containing the arrow files for the labeled (binary) covid classification dataset
LABELED_NER_JSON_FILE_NAME = blobs/labeled_ner_json # the json file where NER labeled rows are save during labeling
LABELED_NER_DATASET_DIR_NAME = arrow_datasets/labeled_ner_dataset # name of the folder containing the arrow files for the NER dataset
LABELED_NER_DATASET_GENERAL_DIR_NAME = arrow_datasets/labeled_ner_dataset_general # name of the folder containing the arrow files for the NER dataset, where there are no subtypes of NE
LABELED_NER_DATASET_NAMESPLIT_DIR_NAME = arrow_datasets/labeled_ner_dataset_namesplit # name of the folder containing the arrow files for the NER dataset where the train and test do not share politicians
LABELED_NER_DATASET_NAMESPLIT_GENERAL_DIR_NAME = arrow_datasets/labeled_ner_dataset_namesplit_general # name of the folder containing the arrow files for the NER dataset where the train and test do not share politicians, and there are no subtypes of NE
LABELED_TITLE_DESC_MATCH_DATASET_DIR_NAME = arrow_datasets/labeled_title_desc_match_dataset # name of the dataset containing the arrow files for labeled dataset with some descriptions shuffles, so they don't match the title

PRETRAINED_ROBERTA_MODEL_RAND_BASE_DIR_NAME = models/roberta_sciride_news_rand_base # name of the folder containing the pretrained roberta model trained only on news
PRETRAINED_ROBERTA_MODEL_GEN_BASE_DIR_NAME = models/roberta_sciride_news_gen_base # name of the folder containing the pretrained roberta model trained on news on top of generic base
FINE_TUNED_MODEL_COVID_DIR_NAME = models/fine_tuned_covid # name of the folder containing the fine tuned model for COVID sequence classification
FINE_TUNED_MODEL_COVID_SUB_DIR_NAME = models/fine_tuned_covid_sub # same as FINE_TUNED_MODEL_COVID_DIR_NAME but with keywords substituted for something else during training
FINE_TUNED_MODEL_POLIT_DIR_NAME = models/fine_tuned_polit # name of the folder containing the fine tuned model for multi-label sequence classification
FINE_TUNED_MODEL_POLIT_SUB_DIR_NAME = models/fine_tuned_polit_sub # same as FINE_TUNED_MODEL_POLIT_DIR_NAME but with keywords substituted for something else during training
FINE_TUNED_MODEL_NER_DIR_NAME = models/fine_tuned_ner # name of the folder containing the fine_tuned model for token classfication
FINE_TUNED_MODEL_TITLE_DESC_MATCH_DIR_NAME = models/fine_tuned_title_desc_match # name of the folder containing the fine_tuned model for "title matches description"

PRETRAINED_GPT_MODEL_RAND_BASE_DIR_NAME = models/gpt_sciride_news_rand_base # name of the folder containing the GPT model trained only on news
PRETRAINED_GPT_MODEL_GEN_BASE_DIR_NAME = models/gpt_sciride_news_gen_base # name of the folder containing the GPT model trained on news on top of generic base